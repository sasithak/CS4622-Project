# -*- coding: utf-8 -*-
"""190332D_ML_Project_Label_12.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wquBjOfLXBXNCyUPI1uqcFJXXpxnZDhJ
"""

from google.colab import drive
drive.mount('/content/drive')

# Loading data
import pandas as pd
train = pd.read_csv("/content/drive/My Drive/Semester7/ML/Project/Layer_12/train.csv")
valid = pd.read_csv("/content/drive/My Drive/Semester7/ML/Project/Layer_12/valid.csv")
test = pd.read_csv("/content/drive/My Drive/Semester7/ML/Project/Layer_12/test.csv")

train.head()

valid.head()

test.head()

"""##Distribution of labels

#Handling Missing Values

##Missing values in training data
"""

# Check for missing values in each label
labels = ["label_1", "label_2", "label_3", "label_4"]
train[labels].isnull().sum()

len(train["label_2"])

from sklearn.impute import SimpleImputer

imputer = SimpleImputer(strategy='mean')
columns = ["label_2"]
imputer.fit(train[columns])

# Insert the missing values with the mean with the nearest integer
train[columns] = imputer.transform(train[columns]).round().astype("int")

# Recheck for missing values in each label to confirm whether there are no missing values left
train[labels].isnull().sum()

"""##Missing values in validation data"""

valid[labels].isnull().sum()

len(valid["label_2"])

imputer = SimpleImputer(strategy='mean')
columns = ["label_2"]
imputer.fit(valid[columns])

# Insert the missing values with the mean with the nearest integer
valid[columns] = imputer.transform(valid[columns]).round().astype("int")
valid[labels].isnull().sum()

"""#Label 1 - Speaker ID"""

# Split X and Y
x_label_1 = train.iloc[:, : -4]
y_label_1 = train["label_1"]
x_valid_label_1 = valid.iloc[:, : -4]
y_valid_label_1 = valid["label_1"]

x_label_1.head()

y_label_1.head()

x_test_label_1 = test.iloc[:, 1:]
x_test_label_1.head()

"""##Class Distribution"""

import matplotlib.pyplot as plt

def plot_class_distribution(y):
  label_counts = y.value_counts()
  plt.figure(figsize=(12, 6))
  label_counts.plot(kind='bar')
  plt.xlabel('Value')
  plt.ylabel('Count')
  plt.title('Class Distribution')
  plt.xticks(rotation=45)
  plt.show()

plot_class_distribution(y_label_1)

"""`label 1` shows an even class distribition.

##Feature Selection
###Check for columns with low variance
"""

from sklearn.feature_selection import VarianceThreshold

def variance_check(x: pd.DataFrame, variance: float) -> []:
  try:
    var_thres = VarianceThreshold(variance)
    var_thres.fit(x)

    const_columns = [column for column in x.columns
                        if column not in x_label_1.columns[var_thres.get_support()]]

    print(f"The number of constant columns is {len(const_columns)}.")
    return const_columns

  except ValueError:
    print(f"No feature exists with variance grater than {variance}.")
    return []

const_columns_label_1 = variance_check(x_label_1, 0.3)

const_columns_label_1 = variance_check(x_label_1, 0.2)

const_columns_label_1 = variance_check(x_label_1, 0.13)

const_columns_label_1 = variance_check(x_label_1, 0.12)

"""Almost all columns have lower variance than 0.13. Therefore, I could not take any feature selection decision based on the variance.

###Check for correlation between features
"""

def correlation_check(x: pd.DataFrame, threshold: float) -> set:
  correlated_features = set()
  correlation_matrix = x.corr()
  for i in range(len(x.columns)):
      for j in range(i):
          if abs(correlation_matrix.iloc[i, j]) > threshold:
              colname = correlation_matrix.columns[i]
              correlated_features.add(colname)
  return correlated_features

corr = correlation_check(x_label_1, 0.95)
print(len(corr))

corr = correlation_check(x_label_1, 0.9)
print(len(corr))

"""There are 70 features with correlation value greater than 0.9. Dropping those columns."""

corr

x_label_1 = x_label_1.drop(corr, axis = 1)

x_valid_label_1 = x_valid_label_1.drop(corr, axis = 1)

x_test_label_1 = x_test_label_1.drop(corr, axis = 1)

"""###Mutual Information Classification"""

from sklearn.feature_selection import mutual_info_classif

def plot_mi(x: pd.DataFrame, y: pd.DataFrame) -> pd.Series:
  mi = pd.Series(mutual_info_classif(x, y))
  mi = mi.sort_values(ascending=False)
  mi.plot.bar(figsize=(32, 12))
  return mi

def feature_selection_mi(mi: pd.Series, x: pd.DataFrame, threshold: float) -> pd.DataFrame:
  selected_features = mi[mi > threshold]
  print (f"Selected {selected_features.count()} features out of {len(mi)} features.")
  selected_cols = x.columns[selected_features.index]
  print(selected_cols)
  return selected_cols

mi_label_1 = plot_mi(x_label_1, y_label_1)

"""From the shape of the graph, I could not decide a threshold to drop. Therefore, feature selection based on mutual information was not used

##Principal Component Analysis
"""

from sklearn.decomposition import PCA

pca = PCA(n_components = 0.95, svd_solver = 'full')
pca.fit(x_label_1)
x_label_1_selected = pd.DataFrame(pca.transform(x_label_1))
x_valid_label_1_selected = pd.DataFrame(pca.transform(x_valid_label_1))
x_test_label_1_selected = pd.DataFrame(pca.transform(x_test_label_1))
x_label_1_selected.shape

"""##Modelling

###Model Evaluation
"""

from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score
import numpy as np

def eval_model(y_actual: pd.DataFrame, y_predicted: pd.DataFrame, print_metrics = False) -> float:
  accuracy = accuracy_score(y_true = y_actual, y_pred = y_predicted)
  f_score = f1_score(y_true = y_actual, y_pred = y_predicted, average = 'weighted')

  print(f"Accuracy:      {accuracy:.4f}")
  print(f"F1 Score:      {f_score:.4f}")

  return f_score

from sklearn.model_selection import cross_val_score

def scorer(estimator: any, X: pd.DataFrame, y: pd.DataFrame):
  y_pred = estimator.predict(X)
  f1_score = eval_model(y, y_pred)
  return f1_score

label_1_scores = []

"""###KNN Model"""

from sklearn.neighbors import KNeighborsClassifier

def knn_model(x_train: pd.DataFrame, y_train: pd.DataFrame, x_valid: pd.DataFrame, y_valid: pd.DataFrame, k: int):
  knn = KNeighborsClassifier(n_neighbors = k)
  f_score = cross_val_score(knn, x_train, y_train, cv = 5, scoring = scorer)
  knn.fit(x_train, y_train)
  y_pred = knn.predict(x_valid)
  print("\nValidation:")
  eval_model(y_valid, y_pred, True)
  return [knn, f_score]

knn_label_1, f_score_knn_label_1 = knn_model(x_label_1_selected, y_label_1, x_valid_label_1_selected, y_valid_label_1, 13)
avg_f1_score_knn_label_1 = f_score_knn_label_1.mean()
print(f"\nAverage F1 score of KNN cross validation: {avg_f1_score_knn_label_1}.")
label_1_scores.append([knn_label_1, "KNN", avg_f1_score_knn_label_1])

"""###Random Forest Model"""

from sklearn.ensemble import RandomForestClassifier

def rf_model(x_train: pd.DataFrame, y_train: pd.DataFrame, x_valid: pd.DataFrame, y_valid: pd.DataFrame, n_estimators: int, random_state: int):
  rf = RandomForestClassifier(n_estimators = n_estimators, random_state = random_state)
  f_score = cross_val_score(rf, x_train, y_train, cv = 5, scoring = scorer)
  rf.fit(x_train, y_train)
  y_pred = rf.predict(x_valid)
  print("\nValidation:")
  eval_model(y_valid, y_pred, True)
  return [rf, f_score]

rf_label_1, f_score_rf_label_1 = rf_model(x_label_1_selected, y_label_1, x_valid_label_1_selected, y_valid_label_1, 100, 42)
avg_f1_score_rf_label_1 = f_score_rf_label_1.mean()
print(f"\nAverage F1 score of RF cross validation: {avg_f1_score_rf_label_1}.")
label_1_scores.append([rf_label_1, "Random Forest", avg_f1_score_rf_label_1])

"""###XG Boost Model"""

import xgboost as xgb
import torch

def xgb_model_gpu(x_train, y_train, x_valid, y_valid, n_estimators, random_state):
  xgb_gpu = None
  if (torch.cuda.is_available()):
    xgb_gpu = xgb.XGBClassifier(
        n_estimators = n_estimators,
        random_state = random_state,
        tree_method = 'gpu_hist',
        gpu_id = 0,
    )
  else:
    xgb_gpu = xgb.XGBClassifier(n_estimators = n_estimators, random_state = random_state)

  f_score = cross_val_score(xgb_gpu, x_train, y_train, cv = 5, scoring = scorer)
  xgb_gpu.fit(x_train, y_train)
  y_pred = xgb_gpu.predict(x_valid)
  print("\nValidation:")
  eval_model(y_valid, y_pred, True)

  return [xgb_gpu, f_score]

from sklearn.preprocessing import LabelEncoder

label_1_encoder = LabelEncoder()
y_label_1_encoded = label_1_encoder.fit_transform(y_label_1.copy(deep = True))
y_valid_label_1_encoded = label_1_encoder.transform(y_valid_label_1.copy(deep = True))

xgb_label_1, f_score_xgb_label_1 = xgb_model_gpu(x_label_1_selected, y_label_1_encoded, x_valid_label_1_selected, y_valid_label_1_encoded, 50, 42)
avg_f1_score_xgb_label_1 = f_score_xgb_label_1.mean()
print(f"Average F1 score of XGB cross validation: {avg_f1_score_xgb_label_1}.")
label_1_scores.append([xgb_label_1, "XGBoost", avg_f1_score_xgb_label_1])

"""###Support Vector Machine Model"""

from sklearn.svm import SVC

def svm_model(x_train: pd.DataFrame, y_train: pd.DataFrame, x_valid: pd.DataFrame, y_valid: pd.DataFrame, kernel: str):
  svm = SVC(kernel = kernel)
  f_score = cross_val_score(svm, x_train, y_train, cv = 5, scoring = scorer)
  svm.fit(x_train, y_train)
  y_pred = svm.predict(x_valid)
  print("\nValidation:")
  eval_model(y_valid, y_pred, True)
  return [svm, f_score]

kernels = ["linear", "rbf", "poly"]

for i in range(3):
  kernel = kernels[i]
  Kernel = kernel.capitalize()
  print(Kernel)
  svm, f_sc = svm_model(x_label_1_selected, y_label_1, x_valid_label_1_selected, y_valid_label_1, kernel)
  avg_f_sc = f_sc.mean()
  print(f"\nAverage F1 score of SVM {Kernel} cross validation: {avg_f_sc}.")
  label_1_scores.append([svm, f"SVM {Kernel}", avg_f_sc])
  if (i!= 2): print()

"""###Final Model"""

for score in label_1_scores:
  print(score[1:])

def get_best_model(scores):
  max_index = 0
  for i in range(len(scores)):
    if scores[i][2] > scores[max_index][2]:
      max_index = i
  return scores[max_index]

final_model_label_1, final_model_label_1_name, final_model_label_1_f1_score = get_best_model(label_1_scores)
print(f"Selected {final_model_label_1_name} with cross validation score of {final_model_label_1_f1_score}.")

"""##Tuning

###Hyper Paramer Tuning

Since the accuracy score is not enough, using hyper parameter tuning.
Split the training set into two sets for training and validation.
"""

from sklearn.model_selection import RandomizedSearchCV

param_dist_label_1 = {
    'C': np.logspace(-3, 3, 7),
    'gamma': np.logspace(-3, 3, 7)
}

svm_rbf_label_1 = SVC(kernel='rbf', random_state=42)
random_search_label_1 = RandomizedSearchCV(
    svm_rbf_label_1, param_distributions=param_dist_label_1, n_iter=3, cv=3, scoring=scorer, random_state=42, n_jobs=10)
random_search_label_1.fit(x_label_1_selected, y_label_1)

best_params_random_label_1 = random_search_label_1.best_params_
best_score_random_label_1 = random_search_label_1.best_score_
print("Best Hyperparameters (Random Search):", best_params_random_label_1)
print("Best Accuracy (Random Search):", best_score_random_label_1)

from sklearn.model_selection import GridSearchCV

param_grid = {
    'C': [980.0, 990.0, 1000.0, 1010.0, 1020.0],
    'gamma': [0.5, 0.8, 1.0, 2.2, 1.3]
}

random_search_label_1_2 = RandomizedSearchCV(
    svm_rbf_label_1, param_distributions=param_dist_label_1, n_iter=3, cv=3, scoring=scorer, random_state=42, n_jobs=10)
random_search_label_1_2.fit(x_label_1_selected, y_label_1)

best_params_random_label_1_2 = random_search_label_1_2.best_params_
best_score_random_label_1_2 = random_search_label_1_2.best_score_
print("Best Hyperparameters (Random Search):", best_params_random_label_1_2)
print("Best Accuracy (Random Search):", best_score_random_label_1_2)

"""Selecting `C` and `gamma` hyperparameters as 1.0 and 1000.0 respectively."""

best_svm_model_label_1 = SVC(kernel='rbf', C=best_params_random_label_1_2['C'], gamma=best_params_random_label_1_2['gamma'], random_state=42)
best_svm_model_label_1.fit(x_label_1_selected, y_label_1)

y_valid_pred_label_1 = best_svm_model_label_1.predict(x_valid_label_1_selected)
eval_model(y_valid_label_1, y_valid_pred_label_1)

from sklearn.model_selection import train_test_split

x_label_1_train_subset, x_label_1_valid_subset, y_label_1_train_subset, y_label_1_valid_subset = train_test_split(x_label_1_selected, y_label_1, test_size=0.2, random_state=42)

best_svm_model_label_1 = SVC(kernel='rbf', C=best_params_random_label_1_2['C'], gamma=best_params_random_label_1_2['gamma'], random_state=42)
best_svm_model_label_1.fit(x_label_1_train_subset, y_label_1_train_subset)

y_valid_pred_label_1 = best_svm_model_label_1.predict(x_label_1_valid_subset)
eval_model(y_label_1_valid_subset, y_valid_pred_label_1)

def create_csv(y_pred, label_name):
  output_filename = f"/content/drive/My Drive/Semester7/ML/Project/Layer_12/Results/{label_name}.csv"
  combined_data = pd.DataFrame()
  combined_data[label_name] = y_pred
  combined_data.to_csv(output_filename, index=False)

y_test_pred_label_1 = best_svm_model_label_1.predict(x_test_label_1_selected)
create_csv(y_test_pred_label_1, "label_1")

"""#Label 2"""

x_label_2 = train.iloc[:, : -4]
y_label_2 = train["label_2"]
x_valid_label_2 = valid.iloc[:, : -4]
y_valid_label_2 = valid["label_2"]
x_test_label_2 = test.iloc[:, 1:]

"""## Class Distribition"""

plot_class_distribution(y_label_2)

"""The dataset is imbalanced. Therefore resampling is required. SMOTE will be used."""

from imblearn.over_sampling import SMOTE

smote = SMOTE(sampling_strategy='auto', random_state=42)
x_label_2_resampled, y_label_2_resampled = smote.fit_resample(x_label_2, y_label_2)

plot_class_distribution(y_label_2_resampled)

"""##Feature Selection

###Correlation
"""

x_label_2_resampled = x_label_2_resampled.drop(corr, axis = 1)
x_valid_label_2 = x_valid_label_2.drop(corr, axis = 1)
x_test_label_2 = x_test_label_2.drop(corr, axis = 1)

"""###Mutual Information Classification"""

mi_label_2 = plot_mi(x_label_2_resampled, y_label_2_resampled)

"""Similar to the `label_1` cannot drop features using utual information."""

from sklearn.decomposition import PCA

pca_2 = PCA(n_components = 0.95, svd_solver = 'full')
pca_2.fit(x_label_2_resampled)
x_label_2_selected = pd.DataFrame(pca_2.transform(x_label_2_resampled))
x_valid_label_2_selected = pd.DataFrame(pca_2.transform(x_valid_label_2))
x_test_label_2_selected = pd.DataFrame(pca_2.transform(x_test_label_2))
x_label_2_selected.shape

"""##Modelling

###KNN Model
"""

label_2_scores = []

knn_label_2, f_score_knn_label_2 = knn_model(x_label_2_selected, y_label_2_resampled, x_valid_label_2_selected, y_valid_label_2, 13)
avg_f1_score_knn_label_2 = f_score_knn_label_2.mean()
print(f"\nAverage F1 score of KNN cross validation: {avg_f1_score_knn_label_2}.")
label_2_scores.append([knn_label_2, "KNN", avg_f1_score_knn_label_2])

"""###Random Forest Model"""

rf_label_2, f_score_rf_label_2 = rf_model(x_label_2_selected, y_label_2_resampled, x_valid_label_2_selected, y_valid_label_2, 100, 42)
avg_f1_score_rf_label_2 = f_score_rf_label_2.mean()
print(f"\nAverage F1 score of RF cross validation: {avg_f1_score_rf_label_2}.")
label_2_scores.append([rf_label_2, "Random Forest", avg_f1_score_rf_label_2])

"""###XG Boost Model"""

label_2_encoder = LabelEncoder()
y_label_2_encoded = label_2_encoder.fit_transform(y_label_2_resampled.copy(deep = True))
y_valid_label_2_encoded = label_2_encoder.transform(y_valid_label_2.copy(deep = True))

xgb_label_2, f_score_xgb_label_2 = xgb_model_gpu(x_label_2_selected, y_label_2_encoded, x_valid_label_2_selected, y_valid_label_2_encoded, 50, 42)
avg_f1_score_xgb_label_2 = f_score_xgb_label_2.mean()
print(f"\nAverage F1 score of XGB cross validation: {avg_f1_score_xgb_label_2}.")
label_2_scores.append([xgb_label_2, "XGBoost", avg_f1_score_xgb_label_2])

"""###SVM Model"""

kernels = ["linear", "rbf", "poly"]

for i in range(3):
  kernel = kernels[i]
  Kernel = kernel.capitalize()
  print(Kernel)
  svm, f_sc = svm_model(x_label_2_selected, y_label_2_resampled, x_valid_label_2_selected, y_valid_label_2, kernel)
  avg_f_sc = f_sc.mean()
  print(f"\nAverage F1 score of SVM {Kernel} cross validation: {avg_f_sc}.")
  label_2_scores.append([svm, f"SVM {Kernel}", avg_f_sc])
  if (i!= 2): print()

"""##Final Model"""

for score in label_2_scores:
  print(score[1:])

final_model_label_2, final_model_label_2_name, final_model_label_2_f1_score = get_best_model(label_2_scores)
print(f"Selected {final_model_label_2_name} with cross validation score of {final_model_label_2_f1_score}.")

"""##Tuning

###Hyperparameter Tuning
"""

from sklearn.model_selection import RandomizedSearchCV

param_dist = {
    'n_estimators': np.arange(100, 1000, 100),
    'max_depth': [None] + list(np.arange(10, 110, 10)),
    'min_samples_split': [2, 5, 10, 15],
    'min_samples_leaf': [1, 2, 4, 8],
}

rf_model_label_2 = RandomForestClassifier(random_state=42)
random_search_label_2 = RandomizedSearchCV(estimator=rf_model_label_2, param_distributions=param_dist, n_iter=3, cv=3, scoring=scorer, random_state=42, verbose=1, n_jobs=10)
random_search_label_2.fit(x_label_2_selected, y_label_2_resampled)

best_params_label_2 = random_search_label_2.best_params_
best_score_label_2 = random_search_label_2.best_score_

print("Best Hyperparameters:", best_params_label_2)
print("Best Accuracy:", best_score_label_2)

best_rf_model_label_2 = RandomForestClassifier(
    n_estimators=best_params_label_2['n_estimators'],
    max_depth=best_params_label_2['max_depth'],
    min_samples_split=best_params_label_2['min_samples_split'],
    min_samples_leaf=best_params_label_2['min_samples_leaf'],
    random_state=42
)

best_rf_model_label_2.fit(x_label_2_selected, y_label_2_resampled)

y_valid_pred_label_2 = best_rf_model_label_2.predict(x_valid_label_2_selected)
eval_model(y_valid_label_2, y_valid_pred_label_2)

from sklearn.model_selection import train_test_split

x_label_2_train_subset, x_label_2_valid_subset, y_label_2_train_subset, y_label_2_valid_subset = train_test_split(x_label_2_selected, y_label_2_resampled, test_size=0.2, random_state=42)

best_rf_model_label_2 = RandomForestClassifier(
    n_estimators=best_params_label_2['n_estimators'],
    max_depth=best_params_label_2['max_depth'],
    min_samples_split=best_params_label_2['min_samples_split'],
    min_samples_leaf=best_params_label_2['min_samples_leaf'],
    random_state=42
)

best_rf_model_label_2.fit(x_label_2_train_subset, y_label_2_train_subset)

y_valid_pred_label_2 = best_rf_model_label_2.predict(x_label_2_valid_subset)
eval_model(y_label_2_valid_subset, y_valid_pred_label_2)

y_test_pred_label_2 = best_rf_model_label_2.predict(x_test_label_2_selected)
create_csv(y_test_pred_label_2, "label_2")

"""#Label 3"""

x_label_3 = train.iloc[:, : -4]
y_label_3 = train["label_3"]
x_valid_label_3 = valid.iloc[:, : -4]
y_valid_label_3 = valid["label_3"]
x_test_label_3 = test.iloc[:, 1:]

"""##Class Distribution"""

plot_class_distribution(y_label_3)

"""This dataset is also imbalanced. Using SMOTE."""

smote = SMOTE(sampling_strategy='auto', random_state=42)
x_label_3_resampled, y_label_3_resampled = smote.fit_resample(x_label_3, y_label_3)

plot_class_distribution(y_label_3_resampled)

"""##Feature Selection

###Correlation
"""

x_label_3_resampled = x_label_3_resampled.drop(corr, axis = 1)
x_valid_label_3 = x_valid_label_3.drop(corr, axis = 1)
x_test_label_3 = x_test_label_3.drop(corr, axis = 1)

"""###Mutual Information Classification"""

mi_label_3 = plot_mi(x_label_3_resampled, y_label_3_resampled)

"""Observing the graph, drop the features with mutual information score less than to 0.015."""

selected_col_names_label_3 = feature_selection_mi(mi_label_3, x_label_3_resampled, 0.015)

x_label_3_selected = pd.DataFrame(x_label_3_resampled, columns = selected_col_names_label_3)
x_valid_label_3_selected = pd.DataFrame(x_valid_label_3, columns = selected_col_names_label_3)
x_test_label_3_selected = pd.DataFrame(x_test_label_3, columns = selected_col_names_label_3)

"""##Modeling

###KNN Model
"""

label_3_scores = []

knn_label_3, f_score_knn_label_3 = knn_model(x_label_3_selected, y_label_3_resampled, x_valid_label_3_selected, y_valid_label_3, 13)
avg_f1_score_knn_label_3 = f_score_knn_label_3.mean()
print(f"\nAverage F1 score of KNN cross validation: {avg_f1_score_knn_label_3}.")
label_3_scores.append([knn_label_3, "KNN", avg_f1_score_knn_label_3])

"""###Random Forest Model"""

rf_label_3, f_score_rf_label_3 = rf_model(x_label_3_selected, y_label_3_resampled, x_valid_label_3_selected, y_valid_label_3, 100, 42)
avg_f1_score_rf_label_3 = f_score_rf_label_3.mean()
print(f"\nAverage F1 score of RF cross validation: {avg_f1_score_rf_label_3}.")
label_3_scores.append([rf_label_3, "Random Forest", avg_f1_score_rf_label_3])

"""###XG Boost Model"""

label_3_encoder = LabelEncoder()
y_label_3_encoded = label_3_encoder.fit_transform(y_label_3_resampled.copy(deep = True))
y_valid_label_3_encoded = label_3_encoder.transform(y_valid_label_3.copy(deep = True))

xgb_label_3, f_score_xgb_label_3 = xgb_model_gpu(x_label_3_selected, y_label_3_encoded, x_valid_label_3_selected, y_valid_label_3_encoded, 50, 42)
avg_f1_score_xgb_label_3 = f_score_xgb_label_3.mean()
print(f"\nAverage F1 score of XGB cross validation: {avg_f1_score_xgb_label_3}.")
label_3_scores.append([xgb_label_3, "XGBoost", avg_f1_score_xgb_label_3])

"""###SVM Model"""

kernels = ["linear", "rbf", "poly"]

for i in range(3):
  kernel = kernels[i]
  Kernel = kernel.capitalize()
  print(Kernel)
  svm, f_sc = svm_model(x_label_3_selected, y_label_3_resampled, x_valid_label_3_selected, y_valid_label_3, kernel)
  avg_f_sc = f_sc.mean()
  print(f"\nAverage F1 score of SVM {Kernel} cross validation: {avg_f_sc}.")
  label_3_scores.append([svm, f"SVM {Kernel}", avg_f_sc])
  if (i!= 2): print()

"""###Final Model"""

for score in label_3_scores:
  print(score[1:])

final_model_label_3, final_model_label_3_name, final_model_label_3_f1_score = get_best_model(label_3_scores)
print(f"Selected {final_model_label_3_name} with cross validation score of {final_model_label_3_f1_score}.")

y_test_pred_label_3 = final_model_label_3.predict(x_test_label_3_selected)
create_csv(y_test_pred_label_3, "label_3")

"""#Label 4"""

x_label_4 = train.iloc[:, : -4]
y_label_4 = train["label_4"]
x_valid_label_4 = valid.iloc[:, : -4]
y_valid_label_4 = valid["label_4"]
x_test_label_4 = test.iloc[:, 1:]

"""##Class Distribution"""

plot_class_distribution(y_label_4)

"""Dataset is imbalanced. Using SMOTE."""

smote = SMOTE(sampling_strategy='auto', random_state=42)
x_label_4_resampled, y_label_4_resampled = smote.fit_resample(x_label_4, y_label_4)

plot_class_distribution(y_label_4_resampled)

"""##Feature Selection

###Correlation
"""

x_label_4_resampled = x_label_4_resampled.drop(corr, axis = 1)
x_valid_label_4 = x_valid_label_4.drop(corr, axis = 1)
x_test_label_4 = x_test_label_4.drop(corr, axis = 1)

"""###Mutual Information Classification

Since now there is a large number of data points after SMOTE resampling, mutual information classification took a lot of time. Therefore, it was not used.


###Principal Component Analysis
"""

from sklearn.decomposition import PCA

pca = PCA(n_components = 0.95, svd_solver = 'full')
pca.fit(x_label_4_resampled)
x_label_4_selected = pd.DataFrame(pca.transform(x_label_4_resampled))
x_valid_label_4_selected = pd.DataFrame(pca.transform(x_valid_label_4))
x_test_label_4_selected = pd.DataFrame(pca.transform(x_test_label_4))
x_label_4_selected.shape

"""##Modelling

###KNN Model
"""

label_4_scores = []

knn_label_4, f_score_knn_label_4 = knn_model(x_label_4_selected, y_label_4_resampled, x_valid_label_4_selected, y_valid_label_4, 13)
avg_f1_score_knn_label_4 = f_score_knn_label_4.mean()
print(f"\nAverage F1 score of KNN cross validation: {avg_f1_score_knn_label_4}.")
label_4_scores.append([knn_label_4, "KNN", avg_f1_score_knn_label_4])

"""###Random Forest Model"""

rf_label_4, f_score_rf_label_4 = rf_model(x_label_4_selected, y_label_4_resampled, x_valid_label_4_selected, y_valid_label_4, 100, 42)
avg_f1_score_rf_label_4 = f_score_rf_label_4.mean()
print(f"\nAverage F1 score of RF cross validation: {avg_f1_score_rf_label_4}.")
label_4_scores.append([rf_label_4, "Random Forest", avg_f1_score_rf_label_4])

"""###XG Boost Model"""

label_4_encoder = LabelEncoder()
y_label_4_encoded = label_4_encoder.fit_transform(y_label_4_resampled.copy(deep = True))
y_valid_label_4_encoded = label_4_encoder.transform(y_valid_label_4.copy(deep = True))

xgb_label_4, f_score_xgb_label_4 = xgb_model_gpu(x_label_4_selected, y_label_4_encoded, x_valid_label_4_selected, y_valid_label_4_encoded, 50, 42)
avg_f1_score_xgb_label_4 = f_score_xgb_label_4.mean()
print(f"\nAverage F1 score of XGB cross validation: {avg_f1_score_xgb_label_4}.")
label_4_scores.append([xgb_label_4, "XGBoost", avg_f1_score_xgb_label_4])

"""###SVM Model"""

kernels = ["linear", "rbf", "poly"]

for i in range(3):
  kernel = kernels[i]
  Kernel = kernel.capitalize()
  print(Kernel)
  svm, f_sc = svm_model(x_label_4_selected, y_label_4_resampled, x_valid_label_4_selected, y_valid_label_4, kernel)
  avg_f_sc = f_sc.mean()
  print(f"\nAverage F1 score of SVM {Kernel} cross validation: {avg_f_sc}.")
  label_4_scores.append([svm, f"SVM {Kernel}", avg_f_sc])
  if (i!= 2): print()

"""###Final Model"""

for score in label_4_scores:
  print(score[1:])

final_model_label_4, final_model_label_4_name, final_model_label_4_f1_score = get_best_model(label_4_scores)
print(f"Selected {final_model_label_4_name} with cross validation score of {final_model_label_4_f1_score}.")

y_test_pred_label_4 = final_model_label_4.predict(x_test_label_4_selected)
create_csv(y_test_pred_label_4, "label_4")

output_filename = f"/content/drive/My Drive/Semester7/ML/Project/Layer_12/Results/final.csv"
final_combined_data = pd.DataFrame()
final_combined_data["ID"] = test["ID"]
for i in range(1, 5):
  label_name = f"label_{i}"
  final_combined_data[label_name] = pd.read_csv(f"/content/drive/My Drive/Semester7/ML/Project/Layer_12/Results/{label_name}.csv")[label_name]
final_combined_data.to_csv(output_filename, index=False)